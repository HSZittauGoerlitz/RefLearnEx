{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly import graph_objects as go\n",
    "from tqdm.notebook import tqdm\n",
    "from DQNagents import DQNagent, DOE\n",
    "from System import System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test-System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Systemaufbau\n",
    "\n",
    "Das Test-System besteht aus einer nichtlinearen Regelstrecke (PT1-Glied). Deren Ausgang wird durch eine Störung (ebenfalls verzögert durch ein PT1-Glied) beeinflusst. Geregelt werden soll die Ausgangsgröße $y$ des Gesamtsystems. Die relevanten Übertragungsfunktionen lauten:\n",
    "\n",
    "$$ F_S = \\frac{y_S}{u_S}= \\frac{K(y_S)}{1 + T_Sp} $$\n",
    "$$ F_Z = \\frac{y_Z}{u_Z} = \\frac{1}{1 + 10T_Sp} $$\n",
    "mit\n",
    "\\begin{align}\n",
    "    K(y_S) &= 0.1\\cdot y_S + 2 \\\\\n",
    "    -5 &\\leq u_S \\leq 5 \\\\\n",
    "    -2 &\\leq u_Z \\leq 2 \\\\\n",
    "    y &= y_S + y_Z \\\\\n",
    "    -8.5 &\\leq y \\leq 21.5\n",
    "\\end{align}\n",
    "\n",
    "Folgende größen werden als messbar angenommen:\n",
    "- $y$\n",
    "- $y_S$\n",
    "- $u_S$\n",
    "- $u_Z$\n",
    "\n",
    "<img src=\"../SFB.png\" alt=\"Signalflussbild des Gesamtsystems\" title=\"Signalflussbild des Gesamtsystems\" />\n",
    "\n",
    "### Herleitung der Solver-Gleichung\n",
    "Z-Transformation der Übertragungsfunktion für PT1-Glieder:\n",
    "\\begin{align}\n",
    "    F(p) = \\frac{y}{u}= \\frac{K}{1 + T\\cdot p} \\\\\n",
    "    F(z) = \\frac{y_k}{u_k} = K \\cdot \\frac{1-a}{z-a}\n",
    "\\end{align}\n",
    "mit\n",
    "$$a = e^{-\\frac{dt}{T}}$$\n",
    "\n",
    "Auflösen nach $y_k$:\n",
    "\\begin{align}\n",
    "    F(z) = \\frac{y_k}{u_k} &= \\frac{K-Ka}{z-a} \\\\\n",
    "    y_k \\cdot (z - a) &= u_k \\cdot (K - Ka) \\\\\n",
    "    y_{k+1} - ay_k  &= u_k \\cdot (K - Ka) \\\\\n",
    "    y_{k+1} - ay_k  &= u_k \\cdot (K - Ka) \\\\\n",
    "    y_{k+1} &= u_k \\cdot (K - Ka) + ay_k\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementierung des System-Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sysMax = System(0, probZ=0)\n",
    "sysMin = System(0, probZ=0)\n",
    "for i in range(10000):\n",
    "    sysMin.uZ = -2\n",
    "    sysMax.uZ = 2\n",
    "    yMin = sysMin.step(-5)\n",
    "    yMax = sysMax.step(5)\n",
    "    if i % 2500 == 0:\n",
    "        print(\"yMin: {0:.2f}; yMax: {1:.2f}\".format(yMin, yMax))\n",
    "\n",
    "wMin = np.round(0.7*yMin, 1)\n",
    "wMax = np.round(0.5*yMax, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-System und Ergebnisdarstellung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test system\n",
    "plant = System(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regler\n",
    "Der selbstlernende Regler wird mittels Deep-Q-Learning Realisiert. Die Implementierung erfolgt in Anlehnung an das DQN Tutorial von pytorch sowie an das entsprechende DeepMind Paper (Lernen von Atari Spielen). Das DQN verfahren ist anders als NFQ lernen ein online Verfahren. Es scheint die Weiterentwicklung des NFQ Verfahrens zu sein und zielt auf eine bessere konvergenz der zu trainierenden Modelle ab. Diese ist insbesondere bei großen KNN von Bedeutung. Daher wurde von DeepMind das Bsp. Atari-Spiele gewählt. Wobei der Input die Pixel-Daten der Spielegrafik waren und entsprechende Faltungsschichten selbstständig die wesentlichen merkmale bestimmen mussten. Da zeitlich korellierte Daten schlecht für das Training sind, werden eine Vielzahl an Datensätzen in einem Speicher (Replay-Memory) abgelegt. Zu jedem Prozessschritt werden eine kleine Anzahl an zufälligen Datenpunkten aus dem Speicher gezogen und das Modell trainiert. Dabei wird das Modell doppelt verwendet. Einmal als in jedem Schritt trainiertes und für die Handlungen konsultierte Modell. Das andere soll Q-werte, welche für das Training als Referenzwerte dienen, vorhersagen. Letzteres wird nur zu wenigen Schritten verbessert. Dabei werden die aktuellen Parameter (Gewichte, etc.) des anderen Modells kopiert.\n",
    "\n",
    "Ein System-Zustand ist durch die Messbaren signale gekennzeichnet: $w, y, y_S, u_S, u_Z$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent mit Erfahrungsspeicher und -modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newAgent = True\n",
    "# hyper parameter\n",
    "nEpoch = 5000\n",
    "nBatch = 100\n",
    "batchSize = 32\n",
    "probW = 0.5 # probability for change of set point\n",
    "\n",
    "memCapacity = 320000\n",
    "\n",
    "eps0 = 1.\n",
    "epsDecay = 500\n",
    "epsMin = 0.05\n",
    "\n",
    "targetUpdate = 250  # rate of epochs for updating target model\n",
    "\n",
    "# max cost per action\n",
    "cMax = 0.1\n",
    "mu = 2.5  # target range for cost function\n",
    "\n",
    "# init agent\n",
    "if newAgent:\n",
    "    agent = DQNagent(6, 7, memCapacity, batchSize,\n",
    "                    eps0, epsMin, epsDecay, targetUpdate)\n",
    "actuator = DOE(plant.uSmin, plant.uSmax)\n",
    "\n",
    "visualisation = True\n",
    "\n",
    "# define helper functions\n",
    "A_CONV = [plant.uSmin * 0.5, plant.uSmin * 0.1, plant.uSmin * 0.05,\n",
    "          0.,\n",
    "          plant.uSmax * 0.05, plant.uSmax * 0.1, plant.uSmax * 0.5]\n",
    "\n",
    "def getState(w, uS, y, plant, actuator):\n",
    "    return np.array([w, y, plant.yS, uS, plant.uZ, actuator.state])\n",
    "\n",
    "\n",
    "def fillRM(system, actuator, agent, memCapacity, nActions, QbMin):\n",
    "    for _ in range(memCapacity):\n",
    "        aIdx = np.random.randint(nActions)\n",
    "        u = actuator.step(A_CONV[aIdx])\n",
    "        y = system.getEq(u)\n",
    "        state = getState(y, u, y, system, actuator)\n",
    "        agent.remember(state, aIdx, QbMin, state, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different cost functions\n",
    "def costSimple(w, y, eps=0.5):\n",
    "    if np.abs(w-y) < eps:\n",
    "        return 0\n",
    "    else:\n",
    "        return 0.01\n",
    "\n",
    "\n",
    "def costSmooth(w, y, cMax=0.01, mu=0.5):\n",
    "    e = np.abs(w-y)\n",
    "    omega = np.tanh(np.sqrt(0.95) / mu)\n",
    "\n",
    "    return np.tanh(e*omega)**2. * cMax\n",
    "\n",
    "getCosts = lambda w, y: costSmooth(w, y, cMax=cMax, mu=mu)\n",
    "\n",
    "def getReward(w, y, w_last, y_last, cMax=0.01):\n",
    "\n",
    "    if (abs(w - y) > 2.5) & (abs(w - y) < abs(w_last - y_last)):\n",
    "        reward = cMax / 2.\n",
    "    else:\n",
    "        reward = 0\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if visualisation:\n",
    "    # prepare result visualisation\n",
    "    fig = make_subplots(rows=2, cols=1,\n",
    "                        shared_xaxes=True,\n",
    "                        vertical_spacing=0.02)\n",
    "    fig.update_xaxes(title_text=\"time in s\", row=2, col=1)\n",
    "    fig.update_yaxes(row=1, col=1, title_text=\"plant values\", range=[-9, 22.5])\n",
    "    fig.update_yaxes(row=2, col=1, title_text=\"costs\", range=[0., cMax])\n",
    "\n",
    "    # data\n",
    "    time = np.arange(nBatch) * plant.dt\n",
    "    w = np.zeros(nBatch)\n",
    "    u = np.zeros(nBatch)\n",
    "    y = np.zeros(nBatch)\n",
    "    c = np.zeros(nBatch)\n",
    "\n",
    "    # line objects\n",
    "    lineU = go.Scatter({\"x\": time,\n",
    "                        \"y\": u,\n",
    "                        \"name\": \"u\",\n",
    "                        \"uid\": \"uid_lineU\",\n",
    "                        \"yaxis\": \"y1\",\n",
    "                        \"line\": {\"color\": \"#54A24B\",\n",
    "                                \"width\": 1\n",
    "                                }\n",
    "                        })\n",
    "    lineW = go.Scatter({\"x\": time,\n",
    "                        \"y\": w,\n",
    "                        \"name\": \"w\",\n",
    "                        \"uid\": \"uid_lineW\",\n",
    "                        \"yaxis\": \"y1\",\n",
    "                        \"line\": {\"color\": \"#4C78A8\",\n",
    "                                \"dash\": \"dash\",\n",
    "                                \"width\": 1\n",
    "                                }\n",
    "                        })\n",
    "    lineY = go.Scatter({\"x\": time,\n",
    "                        \"y\": y,\n",
    "                        \"name\": \"y\",\n",
    "                        \"uid\": \"uid_lineY\",\n",
    "                        \"yaxis\": \"y1\",\n",
    "                        \"line\": {\"color\": \"#4C78A8\",\n",
    "                                \"width\": 1\n",
    "                                }\n",
    "                        })\n",
    "    lineC = go.Scatter({\"x\": time,\n",
    "                        \"y\": c,\n",
    "                        \"name\": \"c\",\n",
    "                        \"uid\": \"uid_lineC\",\n",
    "                        \"yaxis\": \"y1\",\n",
    "                        \"line\": {\"color\": \"#000000\",\n",
    "                                \"width\": 1\n",
    "                                }\n",
    "                        })\n",
    "\n",
    "    fig.update_layout(title='', height=800)\n",
    "    # add lines to plots\n",
    "    fig.add_trace(lineU, row=1, col=1)\n",
    "    fig.add_trace(lineW, row=1, col=1)\n",
    "    fig.add_trace(lineY, row=1, col=1)\n",
    "    fig.add_trace(lineC, row=2, col=1)\n",
    "    # create widget\n",
    "    fWidget = go.FigureWidget(fig)\n",
    "    # get direct connection to line data (overwrite variables used for lines)\n",
    "    lineU = fWidget.data[0]\n",
    "    lineW = fWidget.data[1]\n",
    "    lineY = fWidget.data[2]\n",
    "    lineC = fWidget.data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN TRAINING\n",
    "if visualisation:\n",
    "    display(fWidget)\n",
    "# save last reward and training loss of each epoch\n",
    "cEnd = np.zeros(nEpoch)\n",
    "loss = np.zeros(nEpoch)\n",
    "# observe agents min and max Q-Values\n",
    "Qmin = np.zeros(nEpoch)\n",
    "Qmax = np.zeros(nEpoch)\n",
    "\n",
    "wStep = np.round(wMin + (wMax-wMin)*np.random.random(), 1)\n",
    "\n",
    "# fillRM(plant, agent, memCapacity, nActions, QbMin)\n",
    "for epoch in tqdm(range(nEpoch)):\n",
    "    # Initialize the environment and state\n",
    "    plant.reset()\n",
    "    actuator.reset()\n",
    "    uStep = 0\n",
    "    if np.random.random() < probW:\n",
    "        wStep = np.round(wMin + (wMax-wMin)*np.random.random(), 1)\n",
    "    yStep = np.round(yMin + (yMax-yMin)*np.random.random(), 1)\n",
    "    plant.yS = yStep\n",
    "    costs = 0\n",
    "    # get init state\n",
    "    NNstate = getState(wStep, uStep, yStep, plant, actuator)\n",
    "\n",
    "    cEpoch = 0\n",
    "    for batch in range(nBatch):\n",
    "        # Select and perform an action\n",
    "        # use epoch for exploration -> later epochs should be dominated by DQN\n",
    "        aIdx = agent.act(NNstate)\n",
    "        uStep = actuator.step(A_CONV[aIdx])\n",
    "        yStep = plant.step(uStep)\n",
    "\n",
    "        # get immediate costs\n",
    "        costs = getCosts(wStep, yStep)\n",
    "        reward = getReward(wStep, yStep, NNstate[0], NNstate[1])\n",
    "        costs -= reward\n",
    "        if costs < 0.:\n",
    "            costs = 0.\n",
    "        \n",
    "        cEpoch += costs\n",
    "\n",
    "        # get new step in state\n",
    "        NNstateNext = getState(wStep, uStep, yStep, plant, actuator)\n",
    "\n",
    "        if batch + 1 < nBatch:\n",
    "            # Store the transition in memory\n",
    "            agent.remember(NNstate, aIdx, costs, NNstateNext, 0.)\n",
    "            # Train model ANN\n",
    "            agent.replay(epoch)\n",
    "            # save state for next iteration\n",
    "            NNstate = np.copy(NNstateNext)\n",
    "\n",
    "        if visualisation:\n",
    "            # update vis data\n",
    "            u[batch] = uStep\n",
    "            w[batch] = wStep\n",
    "            y[batch] = yStep\n",
    "            c[batch] = costs\n",
    "\n",
    "    agent.remember(NNstate, aIdx, costs, NNstateNext, 1.)\n",
    "\n",
    "    # train agent model\n",
    "    loss[epoch], Qb = agent.replay(epoch, True, epoch==1000)\n",
    "    Qmin[epoch] = Qb[0]\n",
    "    Qmax[epoch] = Qb[1]\n",
    "\n",
    "    cEnd[epoch] = cEpoch\n",
    "\n",
    "    # update visualisation\n",
    "    if visualisation:\n",
    "        with fWidget.batch_update():\n",
    "            lineU.x = time\n",
    "            lineW.x = time\n",
    "            lineY.x = time\n",
    "            lineC.x = time\n",
    "            lineU.y = u\n",
    "            lineW.y = w\n",
    "            lineY.y = y\n",
    "            lineC.y = c\n",
    "            fWidget.layout['title'] = \"Epoch: {}\".format(epoch)\n",
    "        # reset vis data\n",
    "        y *= 0\n",
    "        w *= 0\n",
    "        u *= 0\n",
    "        c *= 0\n",
    "    else:\n",
    "        if (epoch > 0) & (epoch % 500 == 0):\n",
    "            print(\"Current Costs trend: {:.2f}, \"\n",
    "                  \"Std. Deviation in Costs: {:.2f}, \"\n",
    "                  \"Qmin: {:.2f}, Qmax: {:.2f}\"\n",
    "                  .format(cEnd[epoch-500:epoch].mean(), \n",
    "                          cEnd[epoch-500:epoch].std(), \n",
    "                          Qb[0], Qb[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show cost curve and training loss over all epochs\n",
    "# get mean costs to see trends\n",
    "w = 50\n",
    "cEndM = np.convolve(cEnd, np.ones(w), 'full') / w\n",
    "\n",
    "fig = make_subplots(rows=2, cols=1,\n",
    "                    shared_xaxes=True,\n",
    "                    vertical_spacing=0.02)\n",
    "fig.update_xaxes(title_text=\"number of Epoch\", row=2, col=1)\n",
    "fig.update_yaxes(row=1, col=1, title_text=\"Costs\", autorange=True)\n",
    "fig.update_yaxes(row=2, col=1, title_text=\"ANN Loss\", autorange=True)\n",
    "\n",
    "xEpochs = np.arange(nEpoch)\n",
    "lineCostsEnd = go.Scatter({\"x\": xEpochs,\n",
    "                           \"y\": cEnd,\n",
    "                           \"name\": \"costs\",\n",
    "                           \"opacity\": 0.25,\n",
    "                           \"uid\": \"uid_rEndLine\",\n",
    "                           \"yaxis\": \"y1\",\n",
    "                           \"line\": {\"color\": \"#000000\",\n",
    "                                    \"width\": 1\n",
    "                                    }\n",
    "                           })\n",
    "lineCostsEndM = go.Scatter({\"x\": xEpochs,\n",
    "                           \"y\": cEndM,\n",
    "                           \"name\": \"costs mean\",\n",
    "                           \"uid\": \"uid_rEndLine\",\n",
    "                           \"yaxis\": \"y1\",\n",
    "                           \"line\": {\"color\": \"#000000\",\n",
    "                                    \"width\": 1\n",
    "                                    }\n",
    "                           })\n",
    "lineQmin = go.Scatter({\"x\": xEpochs,\n",
    "                       \"y\": Qmin,\n",
    "                       \"name\": \"Qmin\",\n",
    "                       \"uid\": \"uid_lineQmin\",\n",
    "                       \"yaxis\": \"y1\",\n",
    "                       \"line\": {\"color\": \"#CC4F4F\",\n",
    "                                \"width\": 1\n",
    "                                }\n",
    "                       })\n",
    "lineQmax = go.Scatter({\"x\": xEpochs,\n",
    "                       \"y\": Qmax,\n",
    "                       \"name\": \"Qmax\",\n",
    "                       \"uid\": \"uid_lineQmax\",\n",
    "                       \"yaxis\": \"y1\",\n",
    "                       \"line\": {\"color\": \"#1E70CC\",\n",
    "                                \"width\": 1\n",
    "                                }\n",
    "                       })\n",
    "lineLoss = go.Scatter({\"x\": xEpochs,\n",
    "                       \"y\": loss,\n",
    "                       \"name\": \"loss\",\n",
    "                       \"uid\": \"uid_lineLoss\",\n",
    "                       \"yaxis\": \"y1\",\n",
    "                       \"line\": {\"color\": \"#D83C20\",\n",
    "                                \"width\": 1\n",
    "                               }\n",
    "                       })\n",
    "fig.update_layout(title='', height=800)\n",
    "fig.add_trace(lineCostsEnd, row=1, col=1)\n",
    "fig.add_trace(lineCostsEndM, row=1, col=1)\n",
    "fig.add_trace(lineQmin, row=1, col=1)\n",
    "fig.add_trace(lineQmax, row=1, col=1)\n",
    "fig.add_trace(lineLoss, row=2, col=1)\n",
    "cEndWidget = go.FigureWidget(fig)\n",
    "cEndWidget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "nTest = 6000  # number of test steps\n",
    "# switch of exploration\n",
    "agent.EpsilonEnd = 0\n",
    "agent.EpsilonStart = agent.EpsilonEnd\n",
    "agent.Epsilon = 0\n",
    "\n",
    "# data for visualisation\n",
    "time = np.arange(nTest) * plant.dt / 60.\n",
    "w = np.zeros(nTest)\n",
    "u = np.zeros(nTest)\n",
    "y = np.zeros(nTest)\n",
    "\n",
    "# prepare some set points\n",
    "wTest = [0.25*wMax, 0.5*wMax, 0.5*wMin, 0.75*wMin, \n",
    "         0.1*wMax, 0.25*wMin, 0.75*wMax, 0]\n",
    "wStep = int(np.round(nTest / len(wTest)))\n",
    "for i, wt in enumerate(wTest[:-1]):\n",
    "    w[i*wStep:(i+1)*wStep] = wt\n",
    "w[(i+1)*wStep:] = wTest[-1]\n",
    "# reset system\n",
    "plant.reset()\n",
    "actuator.reset()\n",
    "# get init state\n",
    "uStep = 0\n",
    "wStep = w[0]\n",
    "yStep = plant.yS + plant.yZ\n",
    "NNstate = getState(wStep, uStep, yStep, plant, actuator)\n",
    "for stepIdx in range(nTest):\n",
    "    wStep = w[stepIdx]\n",
    "    aIdx = agent.act(NNstate)\n",
    "    uStep = actuator.step(A_CONV[aIdx])\n",
    "    yStep = plant.step(uStep)\n",
    "    # update state\n",
    "    NNstate = getState(wStep, uStep, yStep, plant, actuator)\n",
    "\n",
    "    # update vis data\n",
    "    y[stepIdx] = yStep\n",
    "    u[stepIdx] = uStep\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter({\"x\": time,\n",
    "                          \"y\": u,\n",
    "                          \"name\": \"u\",\n",
    "                          \"uid\": \"uid_lineU\",\n",
    "                          \"line\": {\"color\": \"#54A24B\",\n",
    "                                   \"width\": 1\n",
    "                                  }\n",
    "                          }))\n",
    "fig.add_trace(go.Scatter({\"x\": time,\n",
    "                          \"y\": w,\n",
    "                          \"name\": \"w\",\n",
    "                          \"uid\": \"uid_lineW\",\n",
    "                          \"line\": {\"color\": \"#4C78A8\",\n",
    "                                   \"dash\": \"dash\",\n",
    "                                   \"width\": 1\n",
    "                                  }\n",
    "                          }))\n",
    "fig.add_trace(go.Scatter({\"x\": time,\n",
    "                          \"y\": y,\n",
    "                          \"name\": \"y\",\n",
    "                          \"uid\": \"uid_lineY\",\n",
    "                          \"line\": {\"color\": \"#4C78A8\",\n",
    "                                   \"width\": 1\n",
    "                                  }\n",
    "                          }))\n",
    "fig.update_xaxes(title_text=\"Time in Min\")\n",
    "fig.update_yaxes(title_text=\"Control Values\", autorange=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.saveModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('AI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 3,
  "vscode": {
   "interpreter": {
    "hash": "de5673f08cc042fd69b2464ab01c30abd62c4f4f16485517573956c9832f4ccd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
